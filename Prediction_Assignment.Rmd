---
title: "Prediction Assignment Writeup"
output: html_document
---

This script is to predict the manner in which person did the exercise.

The data used come from this source: http://groupware.les.inf.puc-rio.br/har

The caret package was used, and the Random Forest method was applied.

```{r}

#--------reading data-------------
training = read.csv("/Users/weixinxu/Downloads/pml-training.csv",fill=TRUE, na.strings = c("NA"," ", "NAN",""), stringsAsFactors = FALSE, quote ="\"")
testing =  read.csv("/Users/weixinxu/Downloads/pml-testing.csv",fill=TRUE, na.strings = c("NA", " ", "NAN",""), stringsAsFactors = FALSE,quote ="\"")

#-------check data---------------
# training data: 19622 records and 160 columns
# testing  data: 20    recrods and 160 columns

#dim(training)
#str(training)
#dim(testing)
#str(testing)

# count number of NAs per column
noNA_col=apply(training, 2, function(x) sum(is.na(x)))

# remove columns with more than 40%, i.e., 19622*40%=7848
ntot=nrow(training)    #  total 19622 recrods in the training data
training_2 = training[, !(noNA_col>ntot*0.4)] 
apply(training_2, 2, function(x) sum(is.na(x)))


#---------feature selection-------------
#table(training_2$new_window)
#table(training_2$num_window)
#table(training_2$classe)
# remove those non-related input variables 
training_2$user_name = NULL
training_2$X = NULL    # remove the row number
training_2$raw_timestamp_part_1 = NULL
training_2$raw_timestamp_part_2 = NULL
training_2$cvtd_timestamp = NULL
training_2$new_window = NULL

# change the target variable from string type to factor type
training_2$classe = as.factor(training_2$classe)


# remove higly correlated columns, cutoff=0.85
set.seed(123)
library(caret)
library(mlbench)
correlationMatrix = cor(subset(training_2, select=-c(classe)))
highlyCorrelated = findCorrelation(correlationMatrix, cutoff = 0.85)

# get the final training data after removing highly correlated columns.
training_2_reduce = training_2[, -c(highlyCorrelated)]


# split data into 75% training data, and 25% test data
inTrain = createDataPartition(training_2_reduce$classe, p=0.75, list=FALSE)
training_2_reduce_train = training_2_reduce[inTrain, ]
training_2_reduce_test  = training_2_reduce[-inTrain, ]


#-------build the random forest model with cross validation
control2 = trainControl(method="cv", number = 5)
rf_model = train(classe~., data=training_2_reduce_train, method="rf", trControl=control2, prox=TRUE)

#-------check the input variable importance
plot(varImp(rf_model), main="variable Importance of Top 20", top=20)

#------expect the in sample error
pred1_rf = predict(rf_model, newdata = training_2_reduce_train)
max1=table(prediction=pred1_rf,Actual=training_2_reduce_train$classe) 
in_sample_errorRate = 1 - (sum(diag(max1)) / length(training_2_reduce_train$classe))
in_sample_errorRate
#------expect the out of sample error
pred2_rf = predict(rf_model, newdata = training_2_reduce_test)
max2 = table(prediction=pred2_rf, Actual=training_2_reduce_test$classe)
out_of_sample_errRate = 1- (sum(diag(max2)) / length(training_2_reduce_test$classe))
out_of_sample_errRate  
# predict the 20 test cases
prediction_sample = predict(rf_model, testing)
prediction_sample
```